import streamlit as st
import webbrowser
st.set_page_config(layout="wide")




st.title("Dashboards")

st.write(
    "Explore interactive dashboards created by the EDA team, along with inferences from the data. "
    "Gain valuable insights into waste management trends and patterns."
)

# Creating tabs
tab1, tab2, tab3, tab4 = st.tabs(
    ['Waste Generated Nationally', 'Waste Generated by State', 'Hazardous Waste', 'Geospatial Data'])

with tab1:
    st.markdown(
        f'<h1 style="text-align: center;">Waste Generated Nationally</h1>',
        unsafe_allow_html=True
    )
    # st.header("Waste Generated Nationally")
    # import pygwalker as pyg
    # import pandas as pd
    # from gensim import corpora, models
    # import gensim
    # from sklearn.feature_extraction.text import CountVectorizer
    # import nltk
    # nltk.download('punkt')
    # from sumy.parsers.plaintext import PlaintextParser
    # from sumy.nlp.tokenizers import Tokenizer
    # from sumy.summarizers.lex_rank import LexRankSummarizer

    # df = pd.read_csv("data/waste_generated_32161-0001.csv", encoding='ISO-8859-1')
    # df.dropna(inplace = True)

    # vectorizer = CountVectorizer()
    # X = vectorizer.fit_transform(df['types_of_waste'].values)

    # corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)

    # id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())
    # lda = models.LdaModel(corpus, num_topics=30, id2word=id2word, passes=15)

    # df['Topic_Label'] = [max(lda.get_document_topics(item), key=lambda x: x[1])[0] for item in corpus]
    # df['Topic_Label'].unique()

    # num_topics = 30
    # for topic_id in range(num_topics):
    #     sample_waste_types = df[df['Topic_Label'] == topic_id]  
    #     ['types_of_waste'].sample(5)  
    #     print(f"Topic {topic_id}:")
    #     for waste_type in sample_waste_types:
    #         print(waste_type)
    #     print("\n")

    # summarizer = LexRankSummarizer()

    # category_names = {}

    # Iterate over each unique topic label
    # for topic_id in df['Topic_Label'].unique():
        # Get all waste types for the current topic
        # topic_text = ' '.join(df[df['Topic_Label'] == topic_id] ['types_of_waste'])

        # Create a plaintext parser
        # parser = PlaintextParser.from_string(topic_text,Tokenizer  ("english"))

        # Summarize the text to generate a category name
        # summary = summarizer(parser.document, sentences_count=1)  

        # Store the generated category name in the dictionary
        # category_names[topic_id] = str(summary[0])
    
    # df['Category_Name'] = df['Topic_Label'].map(category_names)

    # walker4 = pyg.walk(
        # df,
        # spec="data/gw0.json",       
        # use_kernel_calc=True,    
        # use_preview=True,        
    # )

    # data = df.loc[:, ['year', 'Topic_Label', 'generated_waste_quantity']]

    # df1 = pd.DataFrame(df)
    # topic_label_totals = df.groupby('Category_Name')['generated_waste_quantity'].sum().reset_index()


with tab2:
    st.markdown(
            f'<h1 style="text-align: center;">Waste Generated by State</h1>',
            unsafe_allow_html=True
        )
        # st.header("Waste Generated by State")
    
    import streamlit as st
    import pandas as pd
    import pygwalker as  pyg


    # Set page Configurations
    # st.set_page_config(
    #   page_title='PyGWalker Demo',
    #   page_icon=':snake:',
    #   layout='wide',
    #   initial_sidebar_state='expanded'
    # )

    # Load data
    @st.cache_data
    def load_data(url):
      df = pd.read_csv(url,sep=',',encoding='latin1')
      return df

    df = load_data('data/Amount-of Waste-Generated-By-State 32121-0003.csv',)

    # Dispay PygWalker 
    def load_config(file_path):
      with open(file_path,'r') as config_file:
        config_str = config_file.read()
      return config_str

    config = load_config('data/config.json')
    pyg.walk(df,env ='Streamlit',dark='dark',spec=config)


with tab3:
    st.markdown(
        f'<h1 style="text-align: center;">Hazardous Waste</h1>',
        unsafe_allow_html=True
    )
    # from data import dashboard_hazardous_waste
    # dashboard_hazardous_waste.main()
    # st.header("Hazardous Waste")

with tab4:
    # from data import GeoApp
    # GeoApp.main()
    import streamlit as st
    import pandas as pd
    import plotly.express as px
    import geopandas as gpd
    import matplotlib.pyplot as plt
    import plotly.graph_objects as go

    # st.set_page_config(layout="wide")

    #main Dataset
    def load_data():
        data = pd.read_csv("data/GeoData.csv")
        return data
    data = load_data()


    st.markdown(
        f'<h1 style="text-align: center;">Germany<br>Waste-Management Stations<br> GeoSpatial Analysis</h1>',
        unsafe_allow_html=True
    )

    # DataFrame - station counts by state and type
    station_counts = data.groupby(['state', 'station']).size().unstack(fill_value=0)

    # Total stations for each state
    station_counts['Total Stations'] = station_counts.sum(axis=1)

    # Totals for each station type
    station_type_totals = station_counts.sum(axis=0)
    station_type_totals.name = 'Total'
    station_counts = pd.concat([station_counts, station_type_totals.to_frame().T])

    # Station Information Table
    st.markdown(
        f'<h2 style="color: Brown"><br><br>Station Information Table</h2>',
        unsafe_allow_html=True
    )

    # dropdown for states
    selected_states = st.multiselect("Select States", data['state'].unique(), default=data['state'].unique())

    # Filter states
    filtered_data = data[data['state'].isin(selected_states)]

    # table with state-wise station counts
    st.table(station_counts[station_counts.index.isin(selected_states)].reset_index())

    # station counts by state and type
    station_counts_by_type = filtered_data.groupby(['state', 'station']).size().unstack(fill_value=0)

    # total stations for each state
    station_counts_by_type['Total Stations'] = station_counts_by_type.sum(axis=1)



    # Station Information Grid
    st.header(" ")
    st.header(" :blue[Station Information Grid]")
    station_info = [
        {
            'name': 'Landfills',
            'type': 'landfills',
            'color': '#ff4c67'
        },
        {
            'name': 'Waste Disposal Centres',
            'type': 'waste disposal centres',
            'color': '#ef9dff'
        },
        {
            'name': 'Recycling Centres',
            'type': 'recycling centres',
            'color': '#26A288'
        },
        {
            'name': 'Waste Transfer Stations',
            'type': 'waste transfer stations',
            'color': '#86983e'
        }
    ]

    col1, col2 = st.columns(2)

    for info in station_info:
        station_name = info['name']
        station_type = info['type']
        filtered_data_by_type = filtered_data[filtered_data['station'] == station_type]
        station_count = len(filtered_data_by_type)

        # Display station information in a grid cell with styles and spacing
        with col1 if info['name'] in ('Landfills', 'Waste Disposal Centres') else col2:
            st.markdown(
                f'<div class="grid-item" style="background-color: {info["color"]}; padding: 20px; '
                f'border-radius: 5px; color: black; margin-bottom: 20px;">'
                f'<h3 style="color: black;">{station_name}</h3>'
                f'<p style="color: brown;">Total Stations: {station_count}</p>'
                f'</div>',
                unsafe_allow_html=True
            )



    st.header(" ")
    st.header(" :blue[Waste-Stations Distribution]")
    tab41, tab42, tab43, tab44 = st.tabs(
    ['Landfills', 'Waste Disposal Centres', 'Waste Transfer Centres', 'Recycling Centres'])

    with tab41:
        # st.subheader("Landfills")
        st.image("images/LFS.png", width=700)
    with tab42:
        # st.subheader("Waste Disposal Centres")
        st.image("images/WDC.png", width=700)
    with tab43:
        # st.subheader("Waste Transfer Centres")
        st.image("images/WTC.png", width=700)
    with tab44:
        # st.subheader("Recycling Centres")
        st.image("images/RC.png", width=700)
    


    st.header(" ")
    st.header(":blue[Heatmap of States Based on Station Information]")
    heatmap_data = station_counts.iloc[:, :-1]
    fig = go.Figure(data=go.Heatmap(
        z=heatmap_data.values,
        x=heatmap_data.columns,
        y=heatmap_data.index,
        colorscale='Viridis',
        colorbar=dict(title='Station Count'),
    ))

    #x-axis stratching
    fig.update_layout(
        autosize=False,
        width=500,  # Adjust the width as needed
        height=500,  # Adjust the height as needed
    )
    st.plotly_chart(fig, use_container_width=True)

    

